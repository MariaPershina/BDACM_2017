---
title: "Bayesian data analysis & cognitive modeling"
subtitle: "06: MCMC methods"
author: "Michael Franke"
output:
  ioslides_presentation:
    css: mistyle.css
    transition: faster
    widescreen: yes
---

```{r setup, include=FALSE, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, 
                      dev.args = list(bg = 'transparent'), fig.align='center',
                      cache=FALSE)
require('tidyverse')
require('forcats')
theme_set(theme_bw() + theme(plot.background=element_blank()) )
```

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
  var MML = MathJax.ElementJax.mml,
      TEX = MathJax.InputJax.TeX;

  TEX.Definitions.macros.bfrac = "myBevelFraction";

  TEX.Parse.Augment({
    myBevelFraction: function (name) {
      var num = this.ParseArg(name),
          den = this.ParseArg(name);
      this.Push(MML.mfrac(num,den).With({bevelled: true}));
    }
  });
});
</script>


```{r, child = "miincludes.Rmd"}

```


## key notions

- Markov Chain Monte Carlo methods
    - Metropolis Hastings
    - Gibbs
- convergence / representativeness
    - trace plots
    - $\hat{R}$  
- efficiency
    - autocorrelation
    - effective sample size


## recap

Bayes rule for data analysis:

$$\underbrace{P(\theta \, | \, D)}_{posterior} \propto \underbrace{P(\theta)}_{prior} \times \underbrace{P(D \, | \, \theta)}_{likelihood}$$

normalizing constant:

$$ \int P(\theta') \times P(D \mid \theta') \, \text{d}\theta' = P(D) $$

easy to solve only if:

- $\theta$ is a single discrete variable with reasonably sized domain
- $P(\theta)$ is conjugate prior for the likelihood function $P(D \mid \theta)$
- we are very lucky

# approximation by sampling

## example: normal distribution

```{r, fig.align='center', fig.width=5, fig.height=3.5}
# get density values and samples
xVec = seq(-4, 4, length.out = 5000)     # vector of x-coordinates
myPlot = ggplot(tibble(x = rnorm(5000, mean = 0, sd = 1)), aes(x = x)) +  
  geom_density() + 
  geom_line(aes(x = xVec, y = dnorm(xVec, mean = 0, sd = 1)), color = "firebrick") +
  xlab("x") + ylab("(estimated) probability")
myPlot
```

## notation


if $P(\cdot \mid \vec{\alpha}) \in \Delta(X)$ is a distribution over $X$ (possibly high-dimensional) with fixed parameters $\vec{\alpha}$, then write $x \sim P(\vec{\alpha})$
    
- think $x$ is a sample from $P(\vec{\alpha})$

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">examples</span>

- $x \sim \mathcal{N}(\mu,\sigma)$
    - read: "$x$ is normally distributed with mean $\mu$ and SD $\sigma$"
- $\theta \sim \text{Beta}(a,b)$ 
    - read: "$\theta$ comes from a beta distribution with shape $a$ and $b$"

## why simulate?

<span style = "color:firebrick">problem</span>

- assume that $x \sim P$ and that $P$ is "unwieldy"
- we'd like to know some property of $P$ (e.g., function $f(P)$)
    - e.g., mean/median/sd, 95% HDI, cumulative probability $\int_{0.8}^\infty P(x) \ \text{d}x$, $\dots$
    

<span style = "color:white"> dummy </span>

<span style = "color:firebrick">solution: Monte Carlo simulation</span> 

- draw samples $S = x_1, \dots x_n \sim P$
- calculate $f(S)$ (analog of $f(P)$ but for samples)
- for many $f$, $f(S)$ will approximate $f(P)$ if $S$ is "representative" of $P$


# Markov chains

## Markov chain

<span style = "color:white"> &nbsp; </span>


<div style = "float:left; width:55%;">

<span style = "color:firebrick">intuition</span>

a sequence of elements, $x_1, \dots, x_n$ such that every $x_{i+1}$ depends only on its predecessor $x_i$
(think: <span style = "color:firebrick">probabilistic FSA</span>)

  
</div>
<div style = "float:right; width:35%;">
  
<div align = 'center'>
<img src="pics/probabilistic_automaton.png" alt="probabilistic automaton" style="width: 250px;"/>
</div>

</div>

<span style = "color:white"> &nbsp; </span>

<span style = "color:white"> &nbsp; </span>

<span style = "color:white"> &nbsp; </span>

<span style = "color:white"> &nbsp; </span>

<p></p>

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">Markov property</span>

$$ P(x_{n+1} \mid x_1, \dots, x_n) = P(x_{n+1} \mid  x_n) $$


## Markov Chain Monte Carlo methods

get sequence of samples $x_1, \dots, x_n$ s.t.

1. sequence has the <span style = "color:firebrick">Markov property</span> ($x_{i+1}$ depends only on $x_i$), and
2. the <span style = "color:firebrick">stationary distribution</span> of the chain is $P$.

<span style = "color:white">dummy</span>

<span style = "color:firebrick">consequences of Markov property</span>

- non-independence -> autocorrelation <div style="float: right; margin: 0px;">`r emo::ji(":(")`</div>
- easy proof that stationary distribution is $P$ <div style="float: right; margin: 0px;">`r emo::ji(":)")`</div>
- we can work with non-normalized probabilities <div style="float: right; margin: 0px;">`r emo::ji(":)")`</div>
    
# Metropolis Hastings

## island hopping

<div align = 'center'>
<img src="http://static.giantbomb.com/uploads/original/1/17015/1455061-monkey2_2010_07_31_21_20_48_28.png" alt="islands" style="width: 500px;"/>
</div>

- set of islands $X = \{x^s, x^b, x^p\}$
- goal: hop around & visit every island $x \in X$ proportional to its population $P(x)$
    - think: "samples" $x \sim P$ 
- problem: island hopper can remember at most 2 islands' population
    - think: we don't know the normalizing constant

## Metropolis Hastings

- let $f(x) = \alpha P(x)$ (e.g., unnormalized posterior)
- start at random $x_0$, define probability $P_\text{trans}(x_i \rightarrow x_{i+1})$ of going from $x_{i}$ to $x_{i+1}$
    - <span style = "color:firebrick">proposal</span> $P_\text{prpsl}(x_{i+1} \mid x_i)$: prob. of considering jump to $x_{i+1}$ from $x_{i}$
    - <span style = "color:firebrick">acceptance</span> $P_\text{accpt}(x_{i+1} \mid x_i)$: prob of accepting jump to proposal $x_{i+1}$
      $$P_\text{accpt}(x_{i+1} \mid x_i) = \text{min} \left (1, \frac{f(x_{i+1})}{f(x_{i})} \frac{P_\text{prpsl}(x_{i} \mid x_{i+1})}{P_\text{prpsl}(x_{i+1} \mid x_i)} \right)$$
    - <span style = "color:firebrick">transition</span> $P_\text{trans}(x_i \rightarrow x_{i+1}) = P_\text{prpsl}(x_{i+1} \mid x_i) \ P_\text{accpt}(x_{i+1} \mid x_i)$ 

## 7-island hopping

<div class = "centered">
<img src="pics/Kruschke_Fig7_2_MH_Example.png" alt="KruschkeFig7.2" style="width: 410px;"/>
</div>

## 7-island hopping, cont.

<div class = "centered">
<img src="pics/Kruschke_Fig7_3_MH_Example2.png" alt="KruschkeFig7.3" style="width: 510px;"/>
</div>

## properties of MH

- motto: always up, down with probability $\bfrac{f(x^{i+1})}{f(x^{i})}$
- ratio $\bfrac{f(x^{i+1})}{f(x^{i})}$ means that we can neglect normalizing constants
- $P_\text{trans}(x^i \rightarrow x^{i+1})$ defines transition matrix -> Markov chain analysis!
- for suitable proposal distributions:
    - stationary distribution exists (first left-hand eigenvector)
    - every initial condition converges to stationary distribution
    - stationary distribution is $P$

## influence of proposal distribution

<div class = "centered">
<img src="pics/Kruschke_Fig7_4_MH_ProposalWidth.png" alt="KruschkeFig7.4" style="width: 560px;"/>
</div>

# Gibbs sampling

## Gibbs sampling: introduction

- MH is a very general and versatile algorithm
- however in specific situations, other algorithms may be better applicable
    - e.g., when $x \sim P$ is high-dimensional (think: many parameters)
- in such cases, the Gibbs sampler may be helpful
- basic idea: split the multidimensional problem into a series of simpler problems of lower dimensionality

## Gibbs sampling: main idea
- assume $X=(X_1,X_2,X_3)$ and $p(x)=P(x_1,x_2,x_3)$
- start with $x^0=(x_1^0,x_2^0,x_3^0)$
- at iteration $t$ of the Gibbs sampler, we have $x^{i-1}$ and need to generate $x^{i}$
    - $x_1^{i} \sim  P(x_1 \mid x_2^{i-1},x_3^{i-1})$
    - $x_2^{i} \sim  P(x_2 \mid x_1^{i},x_3^{i-1})$
    - $x_3^{i} \sim  P(x_3 \mid x_1^{i},x_2^{i})$
- for a large $n$, $x^n$ will be a sample from $P(x)$
  - $x^n_1$ will be a sample from the <span style = "color:firebrick">marginal distribution</span>  $P(x_1)$:
    
$$ P(x_1) = \int P(\tuple{x_1, x_2, x_3}) \ \text{d} \tuple{x_2, x_3}$$     

## example: 2 coin flips

<div class = "centered">
<img src="pics/Kruschke_Fig7_5_2BetaExample.png" alt="KruschkeFig7.5" style="width: 410px;"/>
</div>

## example: Gibbs jumps

<div class = "centered">
<img src="pics/Kruschke_Fig7_7_Gibbs_Explain.png" alt="KruschkeFig7.7" style="width: 410px;"/>
</div>

## example: Gibbs for 2 coin flips

<div class = "centered">
<img src="pics/Kruschke_Fig7_8_Gibbs_2BetaExample.png" alt="KruschkeFig7.8" style="width: 610px;"/>
</div>

## example: MH for 2 coin flips

<div class = "centered">
<img src="pics/Kruschke_Fig7_6_MH_2BetaExample.png" alt="KruschkeFig7.6" style="width: 610px;"/>
</div>

## summary

- Gibbs sampling can be more efficient than MH
- Gibbs needs samples from conditional posterior distribution
    - MH is more generally applicable
- preformance of MH depends on proposal distribution

clever software helps determine when/how to do Gibbs and how to tune MH's proposal function (next class)

# assessing sample chains

## problem statements

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">convergence/representativeness</span>

- we have samples from MCMC, ideally several chains
- in the limit, samples must be representative of $P$
- how do we know that our meagre finite samples are representative?

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">efficiency</span>

- ideally, we'd like the shortest samples that are representative
- how do we measure that we have "enough" samples?

## packages to compare MCMC chains

```{r}
require('coda')
require('ggmcmc')
```

<div class = "columns-2">

<div align = 'center'>
<img src="http://i.huffpost.com/gen/1063477/original.jpg" alt="islands" style="width: 300px;"/>
</div>

`coda` and `ggmcmc` basically do the same thing, but they differ in, say, aesthetics

`ggmcmc` lives in the tidyverse

</div>


## example MCMC data

```{r, echo = FALSE}
require('coda')

fakeData = rnorm(200, mean = 0, sd = 1)

f = function(mu, sigma){
  if (sigma <=0){
    return(0)
  }
  priorMu = dunif(mu, min = -4, max = 4)
  priorSigma = dunif(sigma, min = 0, max = 4)
  likelihood =  prod(dnorm(fakeData, mean = mu, sd = sigma))
  return(priorMu * priorSigma * likelihood)
}

MH = function(f, iterations = 50, chains = 2, burnIn = 0){
  out = array(0, dim = c(chains, iterations - burnIn, 2))
  dimnames(out) = list("chain" = 1:chains, 
                       "iteration" = 1:(iterations-burnIn), 
                       "variable" = c("mu", "sigma"))
  for (c in 1:chains){
    mu = runif(1, min = -4, max = 4)
    sigma = runif(1, min = 0, max = 4)
    for (i in 1:iterations){
      muNext = mu + runif(1, min = -1.25, max = 1.25)
      sigmaNext = sigma + runif(1, min = -0.25, max = 0.25)
      rndm = runif(1, 0, 1)
      if (f(mu, sigma) < f(muNext, sigmaNext) | f(muNext, sigmaNext) >= f(mu, sigma) * rndm) {
        mu = muNext
        sigma = sigmaNext
      }
      if (i >= burnIn){
        out[c,i-burnIn,1] = mu
        out[c,i-burnIn,2] = sigma
      }
    }
  }
  return(mcmc.list(mcmc(out[1,,]), mcmc(out[2,,])))
}

out = MH(f, 60000,2,10000)
```


```{r}
out = MH(f, iterations = 60000, chains = 2, burnIn = 10000) # self-made MH 
head(out[[1]])      # returns MCMC-list from package 'coda'
```

## example MCMC data

```{r}
out2 = ggs(out)  # cast the same information into a format that 'ggmcmc' uses
out2             # this is now a tibble
```


## trace plots in 'coda'

```{r}
plot(out)
```

## trace plots in 'ggmcmc'

```{r}
ggs_traceplot(out2)
```

## visual inspection of convergence


<span style = "color:white"> &nbsp; </span>

trace plots from multiple chains should look like:

<div align = 'center'>
  a bunch of <span style = "color:firebrick">hairy caterpillars madly in love with each other</span>
</div>

<span style = "color:white"> &nbsp; </span>

<div align = 'center'>
  <img src="pics/caterpillar.png" alt="caterpillar" style="width: 550px;"/>
</div>


## examining sample chains: beginning

<div class = "centered">
<img src="pics/Kruschke_Fig7_10_Diagnostics1.png" alt="KruschkeFig7.10" style="width: 610px;"/>
</div>

## examining sample chains: rest

<div class = "centered">
<img src="pics/Kruschke_Fig7_11_Diagnostics2.png" alt="KruschkeFig7.11" style="width: 610px;"/>
</div>

## burn-in & thinning

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">burn-in</span>

remove initial chunk of sample sequence to discard effects of (random) starting position

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">thinning</span>

only consider every $i$-th sample to remove autocorrelation

## R hat

$\hat{R}$-statistics,

- a.k.a.:
    - Gelman-Rubin statistics
    - shrink factor
    - potential scale reduction factor
- idea:
    - compare variance within a chain to variance between chains
- in practice:
    - use software to compute it
    - aim for $\hat{R} \le 1.1$ for all continuous variables

## R hat in 'coda'

```{r}
gelman.diag(out)
```

## R hat in 'ggmcmc'

```{r}
ggs_Rhat(out2)
```


## autocorrelation

<div class = "centered">
<img src="pics/Kruschke_Fig7_12_Autocorrelation.png" alt="KruschkeFig7.12" style="width: 510px;"/>
</div>

## autocorrelation in 'coda'

```{r , fig.height=2.5}
autocorr.plot(out)
```

## autocorrelation in 'ggmcmc'

```{r}
ggs_autocorrelation(out2)
```

## effective sample size

- intuition:
    - how many samples are "efficient, actual samples" if we strip off autocorrelation

- definition:

$$\text{ESS} = \frac{N}{ 1 + 2 \sum_{k=1}^{\infty} ACF(k)}$$

## effective sample size in 'coda'

```{r}
effectiveSize(out)
```


# fini

## outlook

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">Tuesday</span>

- introduction to JAGS

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">Friday</span>

- 1st practice session


## to prevent boredom

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">obligatory</span>

- prepare Kruschke chapter 8 

<span style = "color:white"> &nbsp; </span>

<span style = "color:firebrick">optional</span>

- install [JAGS](http://mcmc-jags.sourceforge.net) & peak into its documentation
    - careful: most recent JAGS version is 4.2.0, but most recent documentation is for 4.0.0
    
- browse Gelman et al ([2014](http://www.stat.columbia.edu/~gelman/book/)) Part III for more on Bayesian computation
    - more later in this course as well